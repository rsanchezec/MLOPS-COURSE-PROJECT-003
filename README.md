# MLOPS-PROJECT-003

## Resumen del Proyecto

**MLOPS-PROJECT-003** es un proyecto de MLOps que combina Apache Airflow para la orquestaciÃ³n de pipelines con un modelo de machine learning para la predicciÃ³n de supervivencia del Titanic. Este proyecto fue generado usando la CLI de Astronomer y ha sido extendido con componentes personalizados de ML.

## Estructura del Proyecto

```
MLOPS-PROJECT-003/
â”œâ”€â”€ artifacts/                  # Artefactos del modelo y datos
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ random_forest_model.pkl
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ titanic_test.csv
â”‚       â””â”€â”€ titanic_train.csv
â”œâ”€â”€ config/                     # Configuraciones del proyecto
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_config.py
â”‚   â””â”€â”€ paths_config.py
â”œâ”€â”€ dags/                       # DAGs de Apache Airflow
â”‚   â”œâ”€â”€ exampledag.py
â”‚   â”œâ”€â”€ extract_data_from_gcp.py
â”‚   â”œâ”€â”€ extract_data_from_gcp_fixed.py
â”‚   â”œâ”€â”€ simple_etl_dag.py
â”‚   â””â”€â”€ simple_test_dag.py
â”œâ”€â”€ include/                    # Archivos adicionales
â”‚   â””â”€â”€ gcp-key.json          # Credenciales de GCP
â”œâ”€â”€ logs/                       # Logs del sistema
â”‚   â””â”€â”€ log_2025-08-29.log
â”œâ”€â”€ notebook/                   # Notebooks de Jupyter
â”‚   â””â”€â”€ titanic.ipynb
â”œâ”€â”€ pipeline/                   # Pipeline de entrenamiento
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ training_pipeline.py
â”œâ”€â”€ plugins/                    # Plugins de Airflow
â”œâ”€â”€ src/                        # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ feature_store.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ model_training.py
â”œâ”€â”€ templates/                  # Templates HTML para Flask
â”‚   â””â”€â”€ index.html             # Interfaz web principal
â”œâ”€â”€ tests/                      # Pruebas
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ test_dag_example.py
â”œâ”€â”€ application.py              # AplicaciÃ³n Flask principal
â”œâ”€â”€ Dockerfile                  # Imagen Docker de Astro Runtime
â”œâ”€â”€ airflow_settings.yaml      # Configuraciones locales de Airflow
â”œâ”€â”€ packages.txt               # Paquetes del sistema
â”œâ”€â”€ requirements.txt           # Dependencias de Python
â””â”€â”€ setup.py                  # ConfiguraciÃ³n del paquete
```

## Componentes Principales

### ğŸ”„ DAGs de Airflow
- **simple_etl_dag.py**: Pipeline ETL principal
- **extract_data_from_gcp.py**: ExtracciÃ³n de datos desde Google Cloud Platform
- **simple_test_dag.py**: DAG de pruebas

### ğŸŒ AplicaciÃ³n Web Flask
- **application.py**: Servidor Flask con API de predicciones
- **templates/index.html**: Interfaz web interactiva para predicciones
- **Feature Store Integration**: ConexiÃ³n con Redis para almacenamiento de caracterÃ­sticas
- **Data Drift Detection**: Monitoreo automÃ¡tico de deriva de datos usando Alibi Detect

### ğŸ§  Pipeline de Machine Learning
- **data_ingestion.py**: Ingesta y carga de datos
- **data_processing.py**: Procesamiento y transformaciÃ³n de datos
- **model_training.py**: Entrenamiento del modelo
- **feature_store.py**: GestiÃ³n del almacÃ©n de caracterÃ­sticas

### âš™ï¸ ConfiguraciÃ³n
- **database_config.py**: ConfiguraciÃ³n de base de datos
- **paths_config.py**: ConfiguraciÃ³n de rutas del proyecto
- **custom_exception.py**: Excepciones personalizadas
- **logger.py**: Sistema de logging

### ğŸ“Š Monitoreo y MÃ©tricas
- **Prometheus Metrics**: MÃ©tricas de predicciones y deriva de datos
- **Logging Sistema**: Registro detallado de eventos y predicciones
- **Health Checks**: Endpoints para verificar el estado del sistema

## Despliegue Local

### Prerrequisitos
- Docker y Docker Compose
- Astronomer CLI
- Python 3.8+
- Redis (para Feature Store)

### Iniciar el Proyecto

#### 1. Iniciar Airflow
```bash
astro dev start
```

Este comando crearÃ¡ cinco contenedores Docker:

- **Postgres**: Base de datos de metadatos de Airflow
- **Scheduler**: Componente responsable del monitoreo y activaciÃ³n de tareas
- **DAG Processor**: Componente responsable del anÃ¡lisis de DAGs
- **API Server**: Componente responsable de servir la UI y API de Airflow
- **Triggerer**: Componente responsable de activar tareas diferidas

#### 2. Iniciar la AplicaciÃ³n Flask
```bash
python application.py
```

### Acceso a las Aplicaciones

- **Airflow UI**: http://localhost:8080/
- **AplicaciÃ³n Web de Predicciones**: http://localhost:5000/
- **MÃ©tricas de Prometheus**: http://localhost:5000/metrics
- **Servidor de MÃ©tricas**: http://localhost:8000
- **Base de Datos Postgres**: localhost:5432/postgres
  - Usuario: `postgres`
  - ContraseÃ±a: `postgres`

### Comandos Ãštiles

```bash
# Detener el entorno
astro dev stop

# Reiniciar el entorno
astro dev restart

# Ver logs
astro dev logs

# Ejecutar comandos en el contenedor
astro dev bash
```

## TecnologÃ­as Utilizadas

- **Apache Airflow**: OrquestaciÃ³n de workflows
- **Flask**: Framework web para la aplicaciÃ³n de predicciones
- **Python**: Lenguaje de programaciÃ³n principal
- **scikit-learn**: Biblioteca de machine learning
- **pandas**: ManipulaciÃ³n de datos
- **Redis**: Feature Store y almacenamiento en cachÃ©
- **Prometheus**: Monitoreo y mÃ©tricas del sistema
- **Alibi Detect**: DetecciÃ³n de deriva de datos (Data Drift)
- **Docker**: ContenedorizaciÃ³n
- **Google Cloud Platform**: Almacenamiento y servicios en la nube
- **HTML/CSS/JavaScript**: Frontend interactivo

## CaracterÃ­sticas del Modelo ML

El proyecto incluye un modelo de Random Forest para predecir la supervivencia de pasajeros del Titanic:

- **Dataset**: Titanic (train/test)
- **Algoritmo**: Random Forest
- **Objetivo**: ClasificaciÃ³n binaria (supervivencia)
- **Formato del modelo**: Pickle (.pkl)
- **Features utilizadas**: Age, Fare, Pclass, Sex, Embarked, Familysize, Isalone, HasCabin, Title, Pclass_Fare, Age_Fare

## Funcionalidades Avanzadas

### ğŸ” DetecciÃ³n de Deriva de Datos (Data Drift)
- ImplementaciÃ³n de **Kolmogorov-Smirnov Drift** para detectar cambios en la distribuciÃ³n de datos
- Monitoreo automÃ¡tico en tiempo real durante las predicciones
- Alertas y mÃ©tricas cuando se detecta deriva significativa

### ğŸ“Š Sistema de Monitoreo
- **Prometheus Metrics**:
  - `prediction_count`: Contador de predicciones realizadas
  - `drift_count`: Contador de detecciones de deriva
- **Endpoints de mÃ©tricas**: `/metrics` para integraciÃ³n con sistemas de monitoreo
- **Logging detallado**: Registro de eventos, predicciones y alertas

### ğŸª Feature Store con Redis
- Almacenamiento eficiente de caracterÃ­sticas en Redis
- RecuperaciÃ³n rÃ¡pida de datos histÃ³ricos para comparaciÃ³n
- Escalado de datos usando StandardScaler
- GestiÃ³n de lotes de caracterÃ­sticas para entrenamiento

### ğŸŒ Interfaz Web Interactiva
- **Formulario inteligente**: Auto-cÃ¡lculo de campos derivados
- **DiseÃ±o responsive**: Compatible con dispositivos mÃ³viles
- **Tooltips informativos**: Ayuda contextual para cada campo
- **Animaciones CSS**: Experiencia de usuario fluida
- **ValidaciÃ³n en tiempo real**: VerificaciÃ³n de datos antes del envÃ­o

## Despliegue en Astronomer

Para desplegar en Astronomer:

1. Crear una cuenta en Astronomer
2. Seguir la documentaciÃ³n oficial: https://www.astronomer.io/docs/astro/deploy-code/

## Uso de la AplicaciÃ³n

### Predicciones via Web Interface

1. Accede a http://localhost:5000/
2. Completa el formulario con la informaciÃ³n del pasajero:
   - **Datos bÃ¡sicos**: Edad, sexo, clase del boleto, tarifa
   - **InformaciÃ³n familiar**: TamaÃ±o de familia, si viaja solo
   - **Detalles del viaje**: Puerto de embarque, si tiene camarote
   - **Campos derivados**: Se calculan automÃ¡ticamente (Pclass_Fare, Age_Fare)
3. Haz clic en "Realizar PredicciÃ³n"
4. Observa el resultado y las mÃ©tricas de deriva de datos

### API Endpoints

- `GET /`: Interfaz web principal
- `POST /predict`: Endpoint para realizar predicciones
- `GET /metrics`: MÃ©tricas de Prometheus

### Monitoreo del Sistema

```bash
# Ver mÃ©tricas en tiempo real
curl http://localhost:5000/metrics

# Monitorear logs
tail -f logs/log_$(date +%Y-%m-%d).log
```

## Pruebas

Ejecutar las pruebas con:

```bash
# Pruebas de DAGs
python -m pytest tests/dags/

# Validar DAGs
astro dev parse

# Probar la aplicaciÃ³n Flask
python -m pytest tests/ -v
```

## ContribuciÃ³n

1. Fork el proyecto
2. Crear una rama para la feature (`git checkout -b feature/AmazingFeature`)
3. Commit los cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## Soporte

Para reportar bugs o sugerir cambios, contacta al equipo de Astronomer o crea un issue en el repositorio del proyecto.
